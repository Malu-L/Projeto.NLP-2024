# Projeto.NLP-2024

### Recipe Generation with NLP
This project focuses on fine-tuning a natural language processing (NLP) model to generate recipe instructions based on a list of ingredients. The model takes in ingredients as input and produces step-by-step cooking instructions as output.

### Overview
This project fine-tunes a GPT-2 model using a dataset of recipes that includes titles, ingredients, and directions. The goal is to train the model to generate cooking directions based on the ingredients provided by the user.

### Features
Input: A list of ingredients provided by the user.
Output: A recipe with step-by-step instructions generated by the model.
Model: GPT-2 is fine-tuned on a dataset of recipes to learn patterns in ingredient-to-instruction conversion.

### Dataset
The dataset used for fine-tuning contains the following columns:

title: The title of the recipe.
ingredients: The exact quantity and list of ingredients used in the recipe.
directions: The cooking instructions.
link: The source link of the recipe.
source: The source website.
NER: The named entities (ingredients).
The dataset is preprocessed to focus on the ingredients(NER) and directions columns for training.

### Model Fine-Tuning
The model used in this project is GPT-2, which has been fine-tuned using the Hugging Face Transformers library. The fine-tuning process involves:

Tokenization: Tokenizing the input ingredients and directions for training.
Training: Fine-tuning the GPT-2 model on the dataset using the Hugging Face Trainer API.
Evaluation: The fine-tuned model generates instructions based on new, unseen lists of ingredients.